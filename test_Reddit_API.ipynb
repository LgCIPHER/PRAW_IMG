{"cells":[{"cell_type":"markdown","metadata":{"id":"HFJn82OEvcrN"},"source":["(Google Collab file)"]},{"cell_type":"markdown","metadata":{"id":"615XCWKRvj92"},"source":["#Set-up Google Collab (and Install PRAW)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3265,"status":"ok","timestamp":1659422580808,"user":{"displayName":"Long Nguyễn","userId":"11655200550139994868"},"user_tz":-420},"id":"DWguMXjfDmbr","outputId":"7e40ad82-f1c4-49d4-d932-04e44013ab4e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1659422580809,"user":{"displayName":"Long Nguyễn","userId":"11655200550139994868"},"user_tz":-420},"id":"2lXevDYrD79M","outputId":"a41ebff6-e275-44a0-83fd-e96e9f0c0143"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Programming/Python_Program/test_Reddit_API (Google Collab ver)\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/Programming/Python_Program/test_Reddit_API (Google Collab ver)'"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["WorkingPath = \"/content/drive/MyDrive/Programming/Python_Program/test_Reddit_API (Google Collab ver)\"\n","%cd $WorkingPath\n","%pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3481,"status":"ok","timestamp":1659422584283,"user":{"displayName":"Long Nguyễn","userId":"11655200550139994868"},"user_tz":-420},"id":"wiz2bhglyumB","outputId":"a5a53d7c-a4bc-4424-dea6-356b325dbeb0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: praw in /usr/local/lib/python3.7/dist-packages (7.6.0)\n","Requirement already satisfied: prawcore<3,>=2.1 in /usr/local/lib/python3.7/dist-packages (from praw) (2.3.0)\n","Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.7/dist-packages (from praw) (1.3.3)\n","Requirement already satisfied: update-checker>=0.18 in /usr/local/lib/python3.7/dist-packages (from praw) (0.18.0)\n","Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from prawcore<3,>=2.1->praw) (2.23.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.24.3)\n"]}],"source":["!pip install praw"]},{"cell_type":"markdown","metadata":{"id":"0OMD1RuDvuZA"},"source":["#Main code"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11953,"status":"ok","timestamp":1659430780707,"user":{"displayName":"Long Nguyễn","userId":"11655200550139994868"},"user_tz":-420},"id":"RO-reQMpMfEd","outputId":"bd26b9d3-34aa-4260-efeb-7f1bec46c7bb"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n","It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n","See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n","\n"]},{"output_type":"stream","name":"stdout","text":["Starting YelanMains subreddit!\n","\n","--Pass--https://i.redd.it/sysrkzscm5f91.jpg\n","--Pass--https://i.redd.it/5n2heqyv58f91.jpg\n","--Pass--https://i.redd.it/u5o3gilrn7f91.jpg\n","--Pass--https://i.redd.it/p2k1ksi3y1f91.jpg\n","--Pass--https://i.redd.it/9t6okf7wg9f91.png\n","--Pass--https://i.redd.it/2jzf6bpfd6f91.png\n","--Pass--https://i.redd.it/kj6742wltxe91.jpg\n","--Pass--https://i.redd.it/dhxq4x87f8f91.png\n","--Pass--https://i.redd.it/jxorbj71o4f91.png\n","--Pass--https://i.redd.it/pi2dqowld0f91.jpg\n","--Pass--https://i.redd.it/eoe9ep4f0xe91.png\n","--Pass--https://i.redd.it/9viterj1n5f91.png\n","--Pass--https://i.redd.it/v6qjf12p85f91.png\n","--Pass--https://i.redd.it/q83xexlddwe91.jpg\n","--Pass--https://i.redd.it/vnyunznhl4f91.png\n","--Pass--https://i.redd.it/xgqsmwkka3f91.png\n","--Pass--https://i.redd.it/2czk5aqys1f91.jpg\n","--Pass--https://i.redd.it/jvk13alrrve91.jpg\n","--Pass--https://i.redd.it/xf6qe4qvmue91.png\n","--Pass--https://i.redd.it/tb69hqak2qe91.jpg\n","--Pass--https://i.redd.it/d9i9covnate91.jpg\n","--Pass--https://i.redd.it/l41ei7l7aoe91.jpg\n","--Pass--https://i.redd.it/aa95wz3qere91.jpg\n","--Pass--https://i.redd.it/eujp3xcjsue91.png\n","--Pass--https://i.redd.it/jcainjya2ve91.png\n","--Pass--https://i.redd.it/6whgszpzuse91.jpg\n","--Pass--https://i.redd.it/k51zm948mpe91.jpg\n","--Pass--https://i.redd.it/3bgtn6y2bre91.jpg\n","--Pass--https://i.redd.it/k9nowgsvqme91.png\n","--Pass--https://i.redd.it/67sr6wbb8se91.jpg\n","--Pass--https://i.redd.it/feh83w9m3je91.jpg\n","--Pass--https://i.redd.it/3ukbns8q9qe91.png\n","--Pass--https://i.redd.it/x0ttrio4zie91.jpg\n","--Pass--https://i.redd.it/49f8o7r9jpe91.png\n","--Pass--https://i.redd.it/69qoq0i1lje91.png\n","--Pass--https://i.redd.it/xfh959xoffe91.png\n","--Pass--https://i.redd.it/744rumdkzle91.png\n","--Pass--https://i.redd.it/v4ldutlq1ce91.jpg\n","--Pass--https://i.redd.it/8fj5wu7e9je91.png\n","--Pass--https://i.redd.it/1cdezv2giae91.png\n","--Pass--https://i.redd.it/0w58kxrqr7e91.png\n","--Pass--https://i.redd.it/gugxvz6ba9e91.jpg\n","--Pass--https://i.redd.it/s860vhl8ofe91.jpg\n","--Pass--https://i.redd.it/ijjg9iuk2ee91.png\n","--Pass--https://i.redd.it/rnqwm8s6vce91.png\n","--Pass--https://i.redd.it/codaqeql5be91.png\n","--Pass--https://i.redd.it/r6uiu8uf4de91.jpg\n","--Pass--https://i.redd.it/10pjyioub4e91.jpg\n","--Pass--https://i.redd.it/k7fl1b3sgce91.jpg\n","--Pass--https://i.redd.it/qi5auzvmw8e91.png\n","--Pass--https://i.redd.it/6zarix40x2e91.jpg\n","--Pass--https://i.redd.it/6o4h2g9yu0e91.jpg\n","0 new picture has been added!\n","\n","Finish scraping!\n","Start writing into 'new_img.csv' file \n","Done!\n","Start writing into 'Yelan_Mains_img_list.csv' file\n","Finish running!\n","\n","Start scanning 'Yelan_Mains_img_list.csv' file!\n","Keep--https://i.redd.it/sysrkzscm5f91.jpg\n","Keep--https://i.redd.it/5n2heqyv58f91.jpg\n","Keep--https://i.redd.it/u5o3gilrn7f91.jpg\n","Keep--https://i.redd.it/p2k1ksi3y1f91.jpg\n","Keep--https://i.redd.it/9t6okf7wg9f91.png\n","Keep--https://i.redd.it/2jzf6bpfd6f91.png\n","Keep--https://i.redd.it/kj6742wltxe91.jpg\n","Keep--https://i.redd.it/dhxq4x87f8f91.png\n","Keep--https://i.redd.it/jxorbj71o4f91.png\n","Keep--https://i.redd.it/pi2dqowld0f91.jpg\n","Keep--https://i.redd.it/eoe9ep4f0xe91.png\n","Keep--https://i.redd.it/9viterj1n5f91.png\n","Keep--https://i.redd.it/v6qjf12p85f91.png\n","Keep--https://i.redd.it/q83xexlddwe91.jpg\n","Keep--https://i.redd.it/vnyunznhl4f91.png\n","Keep--https://i.redd.it/xgqsmwkka3f91.png\n","Keep--https://i.redd.it/2czk5aqys1f91.jpg\n","Keep--https://i.redd.it/jvk13alrrve91.jpg\n","Keep--https://i.redd.it/xf6qe4qvmue91.png\n","Keep--https://i.redd.it/tb69hqak2qe91.jpg\n","Keep--https://i.redd.it/d9i9covnate91.jpg\n","Keep--https://i.redd.it/l41ei7l7aoe91.jpg\n","Keep--https://i.redd.it/aa95wz3qere91.jpg\n","Keep--https://i.redd.it/eujp3xcjsue91.png\n","Keep--https://i.redd.it/jcainjya2ve91.png\n","Keep--https://i.redd.it/6whgszpzuse91.jpg\n","Keep--https://i.redd.it/k51zm948mpe91.jpg\n","Keep--https://i.redd.it/3bgtn6y2bre91.jpg\n","Keep--https://i.redd.it/k9nowgsvqme91.png\n","Keep--https://i.redd.it/67sr6wbb8se91.jpg\n","Keep--https://i.redd.it/feh83w9m3je91.jpg\n","Keep--https://i.redd.it/3ukbns8q9qe91.png\n","Keep--https://i.redd.it/x0ttrio4zie91.jpg\n","Keep--https://i.redd.it/49f8o7r9jpe91.png\n","Keep--https://i.redd.it/69qoq0i1lje91.png\n","Keep--https://i.redd.it/xfh959xoffe91.png\n","Keep--https://i.redd.it/744rumdkzle91.png\n","Keep--https://i.redd.it/v4ldutlq1ce91.jpg\n","Keep--https://i.redd.it/8fj5wu7e9je91.png\n","Keep--https://i.redd.it/1cdezv2giae91.png\n","Keep--https://i.redd.it/0w58kxrqr7e91.png\n","Keep--https://i.redd.it/gugxvz6ba9e91.jpg\n","Keep--https://i.redd.it/s860vhl8ofe91.jpg\n","Keep--https://i.redd.it/ijjg9iuk2ee91.png\n","Keep--https://i.redd.it/rnqwm8s6vce91.png\n","Keep--https://i.redd.it/codaqeql5be91.png\n","Keep--https://i.redd.it/r6uiu8uf4de91.jpg\n","Keep--https://i.redd.it/10pjyioub4e91.jpg\n","Keep--https://i.redd.it/k7fl1b3sgce91.jpg\n","Keep--https://i.redd.it/qi5auzvmw8e91.png\n","Keep--https://i.redd.it/6zarix40x2e91.jpg\n","Keep--https://i.redd.it/6o4h2g9yu0e91.jpg\n","\n","Finish scanning!\n","0 picture has been removed!\n","\n","Start writing into csv file\n","Finish running!\n"]}],"source":["from praw import Reddit\n","import os.path\n","from pathlib import Path\n","import pickle\n","import requests\n","import cv2 as cv\n","import numpy as np\n","\n","# Higher number = Longer runtime\n","POST_SEARCH_AMOUNT = 100\n","\n","'''Start Global variables'''\n","dir_path = WorkingPath  # Path of this file\n","\n","past_result = []\n","already_done = []\n","last_sub_url_list = []\n","new_img_lst = []\n","\n","lst_img_name = \"Yelan_Mains_img_list.csv\"\n","lst_img_dir = os.path.join(dir_path, lst_img_name)\n","\n","lst_sub_name = \"sub_list.csv\"\n","lst_sub_dir = os.path.join(dir_path, lst_sub_name)\n","\n","new_lst_img_name = \"new_img.csv\"\n","new_lst_img_dir = os.path.join(dir_path, new_lst_img_name)\n","'''End Global variables'''\n","\n","def create_folder(folder_path):  # Create directory if it doesn't exist to save images\n","    CHECK_FOLDER = os.path.isdir(folder_path)\n","    # If folder doesn't exist, then create it.\n","    if not CHECK_FOLDER:\n","        os.makedirs(folder_path)\n","\n","\n","def create_token():  # Create token file\n","    client_id = \"rpemJuwdUD0hyAaQuqTZsw\"\n","    secret = \"h0bUxYugWG8Oilgqh3q9YjpZgPEMZw\"\n","    creds = {}\n","\n","    creds[\"client_id\"] = client_id\n","    creds[\"client_secret\"] = secret\n","    creds[\"user_agent\"] = input(\"user_agent: \")\n","    creds[\"username\"] = input(\"username: \")\n","    creds[\"password\"] = input(\"password: \")\n","\n","    return creds\n","\n","\n","def read_token(dir_path):  # Read token file\n","    # Token file directory\n","    FilePath = os.path.join(dir_path, \"token.pickle\")\n","\n","    file = Path(FilePath)\n","\n","    if file.is_file():\n","        with open(FilePath, 'rb') as token:\n","            creds = pickle.load(token)\n","    else:\n","        creds = create_token()\n","        pickle_out = open(\"token.pickle\", \"wb\")\n","        pickle.dump(creds, pickle_out)\n","\n","    return creds\n","\n","\n","def name_progress(url_str, sub_path, sub):\n","    url_name_lst = url_str.split(\"/\")\n","    pic_name = url_name_lst[3]\n","    pic_name_lst = pic_name.split(\".\")\n","    pic_id = pic_name_lst[0]\n","    pic_type = pic_name_lst[1]\n","\n","    img_name = f\"{sub_path}{sub}-{pic_id}.{pic_type}\"\n","    img_path = os.path.join(sub_path, img_name)\n","\n","\n","def html_to_img(url_str, resize=False):\n","    # Getting image from HTML page\n","    resp = requests.get(url_str, stream=True).raw\n","    image = np.asarray(\n","        bytearray(resp.read()), dtype=\"uint8\")\n","    image = cv.imdecode(image, cv.IMREAD_COLOR)\n","\n","    if resize == True:\n","        # Could do transforms on images like resize!\n","        image = cv.resize(image, (352, 627))\n","\n","    return image\n","\n","\n","def check_deleted_img(url_str):\n","    deleted_flag = False\n","\n","    img = html_to_img(url_str)\n","    [h, w] = [img.shape[0], img.shape[1]]\n","\n","    if [h, w] != [60, 130]:\n","        pass\n","    else:\n","        deleted_flag = True\n","\n","    return deleted_flag\n","\n","\n","def compare_img(url_str, url_list):\n","    ignore_flag = False\n","\n","    img_1 = html_to_img(url_str)\n","    [h_1, w_1] = [img_1.shape[0], img_1.shape[1]]\n","\n","    print(f\"Start comparing--{url_str}\")\n","\n","    for url_done in url_list:\n","        img_2 = html_to_img(url_done)\n","        [h_2, w_2] = [img_2.shape[0], img_2.shape[1]]\n","\n","        if [h_1, w_1] == [h_2, w_2]:\n","            print(f\"--Comparing with--{url_done}\")\n","            difference = cv.subtract(img_1, img_2)\n","            b, g, r = cv.split(difference)\n","            total_difference = cv.countNonZero(\n","                b) + cv.countNonZero(g) + cv.countNonZero(r)\n","            if total_difference == 0:\n","                ignore_flag = True\n","\n","    return ignore_flag\n","\n","\n","def past_list(lst_img_dir):\n","    past_list = []\n","\n","    with open(lst_img_dir, mode=\"r\", encoding=\"utf-8-sig\") as f_past_result:\n","        for line in f_past_result:\n","            url = line.strip()\n","            past_list.append(url)\n","\n","    return past_list\n","\n","\n","def check_available(url_str, already_done):\n","    exist_flag = False\n","\n","    for url_done in already_done:\n","        if url_str == url_done:\n","            exist_flag = True\n","\n","    return exist_flag\n","\n","\n","def Reddit_API():\n","    sub = \"Pixiv\"   # Search for images in this Subreddit\n","\n","    creds = read_token(dir_path)\n","\n","    reddit = Reddit(client_id=creds['client_id'],\n","                    client_secret=creds['client_secret'],\n","                    user_agent=creds['user_agent'],\n","                    username=creds['username'],\n","                    password=creds['password'])\n","\n","    past_result = past_list(lst_img_dir)\n","    for url in past_result:\n","        already_done.append(url)\n","\n","    with open(lst_sub_dir, mode=\"r\", encoding=\"utf-8-sig\") as f_source:\n","        for line in f_source:\n","            sub = line.strip()\n","            subreddit = reddit.subreddit(sub)\n","\n","            count = 0\n","\n","            print(f\"Starting {sub} subreddit!\\n\")\n","\n","            # Searching for Hot post\n","            for submission in subreddit.hot(limit=POST_SEARCH_AMOUNT):\n","                # Get image URL\n","                url_str = str(submission.url.lower())\n","\n","                if \"jpg\" in url_str or \"png\" in url_str:\n","                    exist_flag = False\n","\n","                    exist_flag = check_available(url_str, already_done)\n","\n","                    if exist_flag == False:\n","                        if url_str not in already_done:\n","                            domain_name = submission.domain\n","\n","                            if domain_name != \"imgur.com\":\n","                                try:\n","                                    deleted_flag = False\n","\n","                                    deleted_flag = check_deleted_img(\n","                                        url_str)\n","\n","                                    if not deleted_flag:\n","                                        ignore_flag = False\n","\n","                                        # ignore_flag = compare_img(url_str, last_sub_url_list)\n","\n","                                        if not ignore_flag:\n","                                            new_img_lst.append(url_str)\n","                                            already_done.append(url_str)\n","                                            count += 1\n","                                            print(f\"Add--successfully--{url_str}\")\n","                                    else:\n","                                        print(\"Deleted img\")\n","\n","                                except Exception as e:\n","                                    print(\n","                                        f\"Image failed. {url_str}\")\n","                                    print(e)\n","\n","                            else:\n","                                print(\"Can't deal with Imgur link yet!\")\n","                    else:\n","                        print(f\"--Pass--{url_str}\")\n","\n","            for url_done in already_done:\n","                last_sub_url_list.append(url_done)\n","\n","            print(f\"{count} new picture has been added!\\n\")\n","\n","    print(\"Finish scraping!\")\n","\n","    print(f\"Start writing into '{new_lst_img_name}' file \")\n","\n","    with open(new_lst_img_dir, mode=\"w\", encoding=\"utf-8-sig\") as f_result:\n","        for url_new in new_img_lst:\n","            img_path_str = str(url_new) + \"\\n\"\n","            f_result.write(img_path_str)\n","\n","    print(\"Done!\")\n","\n","    print(f\"Start writing into '{lst_img_name}' file\")\n","\n","    with open(lst_img_dir, mode=\"w\", encoding=\"utf-8-sig\") as f_result:\n","        for url_done in already_done:\n","            img_path_str = str(url_done) + \"\\n\"\n","            f_result.write(img_path_str)\n","\n","    print(\"Finish running!\")\n","\n","\n","def scan_csv():\n","    count = 0\n","\n","    print(f\"\\nStart scanning '{lst_img_name}' file!\")\n","\n","    # past_result = past_list(lst_img_dir)\n","    # for url in past_result:\n","    #     already_done.append(url)\n","\n","    for line in already_done:\n","        url_str = line.strip()\n","        try:\n","            deleted_flag = False\n","\n","            deleted_flag = check_deleted_img(url_str)\n","\n","            if not deleted_flag:\n","                print(f\"Keep--{url_str}\")\n","                # ignore_flag = False\n","\n","                # ignore_flag = compare_img(url_str, already_done)\n","\n","                # if ignore_flag:              \n","                #     already_done.remove(line)\n","                #     count += 1\n","                #     print(f\"Remove--{url_str}\")\n","            else:\n","                already_done.remove(line)\n","                count += 1\n","                print(f\"Remove--{url_str}\")\n","        except Exception as e:\n","            print(f\"Image failed. {url_str}\")\n","            print(e)\n","\n","    print(\"\\nFinish scanning!\")\n","\n","    print(f\"{count} picture has been removed!\\n\")\n","\n","    print(\"Start writing into csv file\")\n","\n","    with open(lst_img_dir, mode=\"w\", encoding=\"utf-8-sig\") as f_result:\n","        for url_done in already_done:\n","            img_path_str = str(url_done) + \"\\n\"\n","            f_result.write(img_path_str)\n","\n","    print(\"Finish running!\")\n","\n","\n","def main():\n","    Reddit_API()\n","    scan_csv()\n","\n","\n","if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"test_Reddit_API.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.9.7 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.7"},"vscode":{"interpreter":{"hash":"dcba00acbf9e1d95ab5965da6517da2c774f8692b740f5482c95e086bac7861d"}}},"nbformat":4,"nbformat_minor":0}